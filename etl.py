# -*- coding: utf-8 -*-
"""ETL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jyhYRZE4Bg2bA81MVVXzhB32BtcGRXxG

# **Data Extraction**

## Amazon Stock data collection from 2018 June until today(2023 June)
"""

# Collecting stock data from different sources for traning our model
#Importing required libraries
import pandas_datareader as pdr

#Source-1 from tiingo
source1 = pdr.get_data_tiingo('AMZN', api_key="661114a49cd0ecde2c565ef415c31d41b2888ee4")

source1.head()

source1.tail()

# source-2 from stooq
# load necessary libraries
import pandas_datareader.data as web
source2 = web.DataReader('AMZN', 'stooq')

source2.head()

source2.tail()

#Source-3 from yahoo finance
import pandas_datareader.data as web
import datetime as dt
import yfinance as yf

source3 = yf.download('GE', start='2018-06-01', end=dt.datetime.today())

source3.head()

source3.tail()

"""# **Feature Selection**"""

source1 = source1[['adjOpen','adjHigh','adjLow','adjClose']]
source1.head()

source2 = source2[['Open','High','Low','Close']]
source2.head()

source3 = source3[['Open','High','Low','Close']]
source3.head()

"""# **DataFrame Formatting**"""

# Correctly formating the order of the source 2 (reversing the order)
import pandas as pd

source2_updated = source2.iloc[::-1]
source2_updated = source2_updated.reset_index(drop=True)
source2_updated.index = source2.index[::-1]
source2_updated.head()

# Converting Source-1 index to proper format
source1.index = source1.index.get_level_values(1).date

source1.head()

# renaming columns properly
source1.columns = ['Open', 'High', 'Low', 'Close']
source1.head()

# Checking all the source frames for proper format
print(source1.head())
print(source2_updated.head())
print(source3.head())

"""# **Data Merging**"""

# Merge all the frames and for duplicate data using average
data = pd.concat([source1, source2_updated, source3])
data.index = pd.to_datetime(data.index)
# Group by the index (assuming the index is the date)
data = data.groupby(data.index).mean()
data.head()

# Converting index to column
data.reset_index(inplace=True)

data.rename(columns={'index': 'Date'}, inplace=True)

data.head()

data['Date'] = data['Date'].astype(str)

import matplotlib.pyplot as plt

data[['Open','High','Low','Close']].plot()
plt.xlabel('Date')
plt.ylabel('Values')
plt.title('Visualizing prices')
plt.legend(loc='best')
plt.show()

"""# **Data Loading**

## Using SQlite database
"""

import sqlite3

conn = sqlite3.connect('stock_database.db')
c = conn.cursor()

# Create table
c.execute('''
    CREATE TABLE stock_data (
        id INTEGER PRIMARY KEY,
        Date TEXT,
        Open REAL,
        High REAL,
        Low REAL,
        Close REAL
    )
''')

# Commit the transaction
conn.commit()

#Inserting into database
# Iterate over DataFrame rows and insert each one into the SQLite table
for _, row in data.iterrows():
    c.execute('''
        INSERT INTO stock_data (Date, Open, High, Low, Close)
        VALUES (?, ?, ?, ?, ?)
    ''', (row['Date'], row['Open'], row['High'], row['Low'], row['Close']))

#commit the changes
conn.commit()

# Open a connection to the SQLite database
conn = sqlite3.connect('stock_database.db')
c = conn.cursor()

# Execute a query to fetch all records from the table
c.execute("SELECT * FROM stock_data Limit 5")

# Fetch all the rows
rows = c.fetchall()

# Iterate over the rows and print them
for row in rows:
    print(row)

# Close the connection
conn.close()

